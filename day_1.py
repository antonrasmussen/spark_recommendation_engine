# DAY 1 QUICK IMPLEMENTATION - MovieLens Recommendation System
# Copy-paste ready code for rapid development

# ============================================================================
# SETUP (30 minutes)
# ============================================================================

# For Google Colab - run this first
!pip install pyspark

# Initialize Spark (works on Colab/Databricks)
from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.sql.functions import *
from pyspark.sql.types import *
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Quick Spark setup
spark = SparkSession.builder \
    .appName("MovieLens-Quick") \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()

print("âœ… Spark initialized successfully!")
print(f"Spark version: {spark.version}")

# ============================================================================
# DATA LOADING (30 minutes) - SIMPLIFIED VERSION
# ============================================================================

# Since you have multiple split files, let's start with a smaller subset for speed
# You can expand to full dataset once everything works

def load_sample_data():
    """
    Load a sample of the data for rapid development
    Start with 1-2 rating files to ensure everything works
    """
    
    # Load movies (single file)
    print("Loading movies...")
    movies = spark.read.csv("movies.csv", header=True, inferSchema=True)
    print(f"Movies loaded: {movies.count():,}")
    
    # Load just first rating file for now (expand later)
    print("Loading ratings sample...")
    ratings = spark.read.csv("ratings_split_1.csv", header=True, inferSchema=True)
    print(f"Ratings loaded: {ratings.count():,}")
    
    # Show sample data
    print("\nSample movies:")
    movies.show(5)
    
    print("\nSample ratings:")
    ratings.show(5)
    
    return movies, ratings

# Execute loading
movies, ratings = load_sample_data()

# ============================================================================
# QUICK DATA EXPLORATION (60 minutes)
# ============================================================================

def quick_data_analysis(movies, ratings):
    """
    Fast data exploration for presentation charts
    """
    print("=" * 50)
    print("QUICK DATA ANALYSIS")
    print("=" * 50)
    
    # Basic stats
    num_movies = movies.count()
    num_ratings = ratings.count()
    num_users = ratings.select("userId").distinct().count()
    
    print(f"Movies: {num_movies:,}")
    print(f"Ratings: {num_ratings:,}")
    print(f"Users: {num_users:,}")
    
    # Rating distribution
    rating_dist = ratings.groupBy("rating") \
                        .agg(count("*").alias("rating_count")) \
                        .orderBy("rating") \
                        .collect()
    
    for row in rating_dist:
        print(f"Rating {row.rating}: {row.rating_count:,} ({row.rating_count/num_ratings*100:.1f}%)")
    
    # User activity (sample)
    print("\nUser Activity Sample:")
    user_activity = ratings.groupBy("userId").count() \
                           .orderBy(desc("count")) \
                           .limit(10)
    user_activity.show()
    
    # Movie popularity (sample)
    print("\nMost Rated Movies:")
    popular_movies = ratings.groupBy("movieId").count() \
                           .join(movies, "movieId") \
                           .orderBy(desc("count")) \
                           .select("title", "count") \
                           .limit(10)
    popular_movies.show(truncate=False)
    
    return rating_dist, user_activity, popular_movies

# Execute analysis
rating_dist, user_activity, popular_movies = quick_data_analysis(movies, ratings)

# ============================================================================
# QUICK VISUALIZATIONS (30 minutes)
# ============================================================================

def create_quick_charts(ratings):
    """
    Generate essential charts for presentation
    """
    # Convert to Pandas for plotting (sample only)
    ratings_sample = ratings.sample(0.1).toPandas()  # 10% sample for speed
    
    plt.figure(figsize=(15, 10))
    
    # Chart 1: Rating Distribution
    plt.subplot(2, 3, 1)
    ratings_sample['rating'].hist(bins=10, edgecolor='black', alpha=0.7)
    plt.title('Rating Distribution')
    plt.xlabel('Rating')
    plt.ylabel('Frequency')
    
    # Chart 2: Ratings per User
    plt.subplot(2, 3, 2)
    user_counts = ratings_sample.groupby('userId').size()
    user_counts.hist(bins=30, edgecolor='black', alpha=0.7)
    plt.title('Ratings per User')
    plt.xlabel('Number of Ratings')
    plt.ylabel('Number of Users')
    plt.yscale('log')
    
    # Chart 3: Ratings per Movie
    plt.subplot(2, 3, 3)
    movie_counts = ratings_sample.groupby('movieId').size()
    movie_counts.hist(bins=30, edgecolor='black', alpha=0.7)
    plt.title('Ratings per Movie')
    plt.xlabel('Number of Ratings')
    plt.ylabel('Number of Movies')
    plt.yscale('log')
    
    # Chart 4: Rating over Time (sample)
    plt.subplot(2, 3, 4)
    ratings_sample['year'] = pd.to_datetime(ratings_sample['timestamp'], unit='s').dt.year
    yearly_ratings = ratings_sample.groupby('year').size()
    yearly_ratings.plot(kind='line')
    plt.title('Ratings Over Time')
    plt.xlabel('Year')
    plt.ylabel('Number of Ratings')
    
    # Chart 5: Average Rating by Movie Count
    plt.subplot(2, 3, 5)
    movie_stats = ratings_sample.groupby('movieId').agg({'rating': ['count', 'mean']}).reset_index()
    movie_stats.columns = ['movieId', 'count', 'avg_rating']
    plt.scatter(movie_stats['count'], movie_stats['avg_rating'], alpha=0.5)
    plt.title('Movie Popularity vs Rating')
    plt.xlabel('Number of Ratings')
    plt.ylabel('Average Rating')
    plt.xscale('log')
    
    plt.tight_layout()
    plt.show()

# Generate charts
create_quick_charts(ratings)

# ============================================================================
# BASIC DATA PREPROCESSING (60 minutes)
# ============================================================================

def quick_preprocessing(ratings):
    """
    Essential preprocessing only
    """
    print("Starting preprocessing...")
    
    # Remove nulls
    clean_ratings = ratings.filter(
        col("userId").isNotNull() & 
        col("movieId").isNotNull() & 
        col("rating").isNotNull()
    )
    
    # Filter for active users (>= 20 ratings)
    user_counts = clean_ratings.groupBy("userId").count()
    active_users = user_counts.filter(col("count") >= 20).select("userId")
    
    # Filter for movies with >= 10 ratings
    movie_counts = clean_ratings.groupBy("movieId").count()
    popular_movies = movie_counts.filter(col("count") >= 10).select("movieId")
    
    # Apply filters
    final_ratings = clean_ratings.join(active_users, "userId") \
                                .join(popular_movies, "movieId")
    
    print(f"Original ratings: {ratings.count():,}")
    print(f"After preprocessing: {final_ratings.count():,}")
    
    # Cache for better performance
    final_ratings.cache()
    
    return final_ratings

# Execute preprocessing
clean_ratings = quick_preprocessing(ratings)

# ============================================================================
# BASIC ALS MODEL (60 minutes)
# ============================================================================

def train_basic_als(ratings):
    """
    Train basic Alternating Least Squares (ALS) model with default parameters
    """
    print("Training basic ALS model...")
    
    # Split data
    (training, test) = ratings.randomSplit([0.8, 0.2], seed=42)
    
    # Cache datasets
    training.cache()
    test.cache()
    
    print(f"Training set: {training.count():,}")
    print(f"Test set: {test.count():,}")
    
    # Configure ALS with reasonable defaults
    als = ALS(
        maxIter=10,                    # Enough for convergence
        regParam=0.01,                 # Standard regularization
        userCol="userId",
        itemCol="movieId", 
        ratingCol="rating",
        coldStartStrategy="drop",      # Handle new users/items
        rank=50                       # Good balance of accuracy/speed
    )
    
    # Train model
    print("Training model...")
    model = als.fit(training)
    print("âœ… Model training complete!")
    
    return model, training, test

# Train the model
model, training, test = train_basic_als(clean_ratings)

# ============================================================================
# BASIC EVALUATION (60 minutes)
# ============================================================================

def quick_evaluation(model, test):
    """
    Basic model evaluation
    """
    print("Evaluating model...")
    
    # Generate predictions
    predictions = model.transform(test)
    
    # Remove NaN predictions
    predictions = predictions.filter(col("prediction").isNotNull())
    
    # Calculate RMSE
    evaluator = RegressionEvaluator(
        metricName="rmse", 
        labelCol="rating", 
        predictionCol="prediction"
    )
    rmse = evaluator.evaluate(predictions)
    
    # Calculate MAE
    mae_evaluator = RegressionEvaluator(
        metricName="mae", 
        labelCol="rating", 
        predictionCol="prediction"
    )
    mae = mae_evaluator.evaluate(predictions)
    
    print(f"âœ… RMSE: {rmse:.4f}")
    print(f"âœ… MAE: {mae:.4f}")
    
    # Show sample predictions
    print("\nSample Predictions:")
    predictions.select("userId", "movieId", "rating", "prediction").show(10)
    
    return predictions, rmse, mae

# Evaluate model
predictions, rmse, mae = quick_evaluation(model, test)

# ============================================================================
# BASIC RECOMMENDATIONS (30 minutes)
# ============================================================================

def generate_sample_recommendations(model):
    """
    Generate sample recommendations for presentation
    """
    print("Generating sample recommendations...")
    
    # Get recommendations for first 10 users
    sample_users = spark.createDataFrame([(i,) for i in range(1, 11)], ["userId"])
    user_recs = model.recommendForUserSubset(sample_users, 5)
    
    print("Sample User Recommendations:")
    user_recs.show(5, truncate=False)
    
    return user_recs

# Generate recommendations
user_recs = generate_sample_recommendations(model)

# ============================================================================
# DAY 1 SUMMARY
# ============================================================================

print("=" * 60)
print("DAY 1 COMPLETION SUMMARY")
print("=" * 60)
print(f"âœ… Environment: Spark {spark.version} running")
print(f"âœ… Data loaded: {clean_ratings.count():,} ratings")
print(f"âœ… Model trained: ALS with RMSE {rmse:.4f}")
print(f"âœ… Charts generated: movielens_quick_analysis.png")
print(f"âœ… Sample recommendations: Generated for 10 users")
print("=" * 60)
print("ðŸŽ¯ READY FOR DAY 2: Model optimization and detailed analysis")
print("=" * 60)

# Save progress (optional)
# model.write().overwrite().save("day1_basic_model")

# Stop Spark (if needed)
# spark.stop()