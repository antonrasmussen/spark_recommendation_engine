Everyone will get started in couple of minutes. Okay, welcome back everyone. So today's agenda is. Let me share my screen. Okay. We will start with Generative AI and project Pan because there I believe, you know, students are having some questions. So we'll, we'll try to address this first and then we will, we'll go to the recommendation engine because your project, the first Project two. Right. This is well coming up. So I want to have this done so that at least you know the material and you know what you're building for project two. And then we'll talk about machine learning and spark something that we need to continue from last class and we'll try to wrap that part as well today. And final thing is the extended lab. Now extended lab is something I didn't post it, but since I told you that, you know, let me go to the canvas. I have told you that there will be one last, you know, one extended lab session in class and that's 20%. It's just like you're a lab. It's a replacement of the assignment I was planning to. I want to build the code and give it to you. You will execute the code because it's going to be a little bit bigger. And we will, we'll do that in the class. So we will do that either in the class or I'm going to release a video. So now the question is like when is the due date? So the due date will be end of next week. But most likely I'm going to release a video for this this week so that we don't have because next week there is a most of the class it would be presentations. So we won't get the chance to do this lab. So I will create a video and I will release that this week with a due date of next week. Right. And I'll make an announcement also for this. So if anybody is having any questions about hey, you know, what is our last assignment? Don't get too much worried about it because it's just a lab, but it's a bigger lab and it's something that you always do when it comes to lab. And I'm also giving a plenty of due date for this. Right. So yeah, I hope there is no questions about that. If you have any questions, just let me know about the extended lab. Okay. So we will also here we will try to address some of the assignment three questions I'm getting from students and which is due next week. So we'll try to address that as well. Now before I start this class, I Want to let you know again I'm making this announcement again, if you have any questions. Right. Regarding office hours. See, my office hours were typically on Wednesdays, 4:30 to 5:30pm But I have extended my office office hours. So this is 4:30pm to 5:25pm I was on Zoom even today. So this is a link you can join. If you have any questions, you have some code problems, GitHub problems or anything, please log in. That way we can save some time going back and forth. And you know, the email sometimes might be tough, so it might be easier to just finish this in the office hours. So this is Monday to Thursday again, I've always told you that you can contact me and we can schedule an appointment. So as long we do that, it should be fine. So before I start this class, anybody has any questions so far? Any anything specific anybody wants to ask? Yeah, professor, sorry, this is Jim. Yeah, it seems like there were three or four of us that were having the issue with the project one. I imagine there's probably many more since we were all getting the same error. I was wondering if you could maybe go over some of the intent of that project or the programming of it. There's a general lack of understanding on what's going on with that. And you know, I've invested several days in this and I'm just not getting anywhere. Okay. Did you watch the video? Did you happen to watch the video which I posted for the lab Genai project? I cannot recall, to be honest with you. I've been in each one of your classes. If it was separate from the class, probably not. Let's revisit that first. So let us go to the project side. Right. So looks like that's the big problem is we. So how many students don't know that there is a video for this? If you have not watched the video, then you are missing a very, very big, you know, chunk of information. I did, I did actually watch the video and I still did have similar issues that James had. Okay, okay, okay. So let me go here and so see as per the instructions here, please see the below video. You can help the executing project under Media Gallery. Let us go to the Media Gallery. Right under the Media Gallery. There should be somewhere Gen AI this one. So this is, you know, here I explain it and sometimes if there are any errors. I see One of the reasons I, I will explain why they choose this project is it's open source project and it's a, you know, very built, very well built Genai project. It includes the state of the art technologies and it's just a lot. And that's why I always, you know, even in the, at the starting, also in the, in the video I tell that even partial execution is fine because if anything breaks with the GitHub or something, that's fine, but at least just show me what error you are getting. But now if you want to really solve the error, then of course, please contact me. From a grading point, I've made it very clear that you know, as long as you're trying to, you know, install things, you make it work and something breaks, just put the error there. Because these things might be a little bit dynamic, but I still want you guys to go and see how the pipeline works and that was my intent. Right? So from a grading point, don't worry too much if something is breaking. As long as you're putting the screenshots and which I will go through today, it is fine. But if you want to learn more, you won't really see that, you know, why is this breaking? And you, you know, you can please contact me and I will try to resolve it because I again, this is a open source project, so if something is breaking, some module, some Python library got broken, it might be out of control. But the big picture, as long you're trying to. Because it has multiple components, not a single component, right? As long as you're like you're doing something on the Wahab cluster, you have installed all the things in the cloud, many parts of the project can run without any issues. There might be some issues when you are actually working with the GitHub, but many things can actually work without any error. So as long as I'm seeing that, you know, you're good from the grading point. But again, if you want to do more and you have questions or concerns, please reach out to me and I'll work with you in the office. We take an appointment. But don't please get worried about this particular project. Whether you know, you lost some, you got some error and it's not letting you do something. Grading will be impacted. No, for this project, no. Right, okay. But anyway, yeah, please go so this. Correct me if I'm wrong, please. So this was basically a get to know the environment type instruction set. Yeah, it's more of like you try to connect all the dots. Right. Okay, so let me actually go through and then maybe it will answer your questions. I'll come back to you. Thank you, professor. So, okay, before I go to that project, let me do one thing. Let me actually introduce you to Genai Right. And, and then we will go to the project. So here, you know, in the modules we have the Gen AI presentation and quickly do. And if anybody, most of you want like extension for this project, please put it in the chat. I just want to see that how many of you want to require extension for this? So these are already there. So first thing is if you're able to see my screen, let's try to see, you know, what is introduction, what is generative AI. Now over the last two years you have probably heard of all these Gen AI words, something called as LLM chatbots. Now rag is something, it's adding some metadata to the large language models. Some. Yeah, let me just take this chat. Okay, okay. And then there is something called as Agent Ki image video generation and defects. But all these buzzwords are coming from the main, you know, I would say that main innovation on the Genai side. Now let's try to see what is, what is Genai and why, why it got so popular at the first place. So in 2022, you know, when ChatGPT got released, that's, that's when you know, this whole generative AI got introduced and it took everybody by storm right. Now not only because, and what did it improve is like because when generative AI came in, it uses a lot of GPUs so you know, the GPU stocks also went up, you know, there was a huge improve, huge increase in the value for Nvidia stocks because they are basically a GPU company. And one thing just for your information, anytime you have a comparison between intel and Nvidia, right? So intel is more focused on the CPU side and Nvidia is more focused on the GPU side. And now if you look at their libraries, machine learning libraries, data science libraries, right? Nvidia tries to provide lot of libraries to help accelerate the machine learning process on the GPUs, right? Because their main product is the GPUs to sell GPUs while Intel, if you look at their data science libraries with machine learning libraries, their focus is to more, you know, create libraries that can allow machine learning based tools to run faster on CPU based. Right? So because everybody is not going to use GPUs always, right? There won't be some code with CPU is there? So how to make machine learning much faster than the cpu, right? This is just additional information I'm trying to tell. Since we are here right now, let me just go through some of the important things here. Yeah, so now what are the tools that Genai basically uses like you know, one is Python. Python is definitely, when you talk about data science AI, ML Python is the most used tool. Again, generative AI is not something different. The roadmap to generative AI, if somebody asks me how do I learn generative AI? So it starts with introduction to data Science, maybe part of big Data. And then you deep learning and then you go to generative AI. So everything is connected. You start with Python basics of programming, then you try go to Intro to Data Science and then deep learning deep learning is must and then you enter into the data science. So knowing these tools is also very much important. And there are pretty much TensorFlow, PyTorch, PyTorch, these are some tools. If you're taking a deep learning course, these tools are must. TensorFlow is a library from Google to build deep learning models. Pytorch again has a deep library from Meta or Facebook previously to build deep learning models. Right. So these tools is a must. Before, if you are entering into the gen space now, another important, very important website in this space is called Hugging Face Transformers. Now we haven't discussed Transformers. Yes, if we have time, we will try to do that. But Transformers is a very, very important deep learning model. And only because it came around somewhere around 2017 or something. And once it came, that's where it's a basic fundamental block of generative A. So again, your chat GPT is nothing but a transformer model. And there are many other models as well. Like, you know, tragedy is not the charge application. The model behind it is called GPT2 GPT3. Right. Similarly, a lot of other models like Gemini, these are called large language models. Basically these, these are very, very big machine learning models. So to be more specific, these are very, very big deep learning models. And deep learning is a subset of machine learning. So they are so big, big in the point means like they are architecturally big. And, and their, you know, data, data is also very, very big. Right. So Transformers was a great innovation in this space. And once the Transformers came, so did the other models followed over it. So let me just quickly go that website to show you where hugging face is because it, it's, it's one of the most followed in the AML community. So if we look at here. Yeah. So hugging face here, right. This is, this is one of the most important websites in the AML space as on today. And let me show you something here. Okay. So here, if you click on it, there are a lot of models especially, you know, most of the models sometimes could be related to this Transformers and transformers from multiple companies like Nvidia could create their own model with transformers and deploy it here. Or Meta could create a transformer model and would deploy it here. So people could go and download these transformer models and try to play around with them. And then there is a lot of data sets also available here. So you can click on tabular data, you can click on image data. Right? There's a lot of good data available, time series data, so. And you can select a different time of formats. Right. So if you are entering into the genes space, hugging space is something you must know. Right. So. And with these keywords you can start exploring more. But these tools are absolutely needed to enter into this space. Now then there is something called OpenCV. Now OpenCV is something. See, if you have seen the ChatGPT models, you can understand that. Initially they were able to understand only documents, right. But later they are able to also understand images. You give an image, ask the description, or maybe you want to create an image from the description. It's able to do all those things. But OpenCV helps with a lot of image pre processing. So a lot of data that is fed into ChatGPT. They would have used OpenCV to build these models, to pre process your images, clean it and then start using it to build the modeling part. Right. So these, again, these tools are extremely important if you want to make a good impact in the genius space. Now, now before, before entering into, you know, discussing more into the generative AI, let's start to discuss what do you think generative AI is? Anybody you know, at a very high level, what do you think generative AI, now you have been doing the project as well. So what do you really think generative AI can do? >> Speaker 2: It's a probability algorithm. >> Speaker 1: Probability algorithm. Okay, what else? But what is its main objective or what is its main feature? If you. It takes a query and generates output based off of data that it was trained on. Generates output. Excellent. So generates output based on the data. Right. Okay. Any other, any other definitions here? ChatGPT as you said? Yeah, if you. Yeah, you can, you can. ChatGPT is basically an application. Behind that there is a model. But yes, you can call ChatGPT as a generative AI application. Yeah, I will say, I will say multiple forms. It can take multiple forms of input and multiple forms of multiple, multiple prompts, forms, I mean text number or. Yes, multiple forms of data can be generated. Yes, excellent. Data can. Okay, now we have been looking at machine learning, so the definitions, what we got is very you know, very, very similar to what I was trying to tell. I just want to add a couple of things and rephrase it a little bit. So till now, you know, you started with data analysis, right? Let me just increase it a little. Yeah, you started with data analysis here, right? Where we are basically understanding the data. Where you did univariate analysis, you know, different type of bivariate analysis, things like that, but that is all about data analysis. But then after you finished your data analysis, then what did we start doing? You know, see, even before data analysis, you were doing spark, but that's a different thing. But in the machine learning world, you start with data analysis. The second thing you're right now doing is the building machine learning pipeline, right? Now, what is machine learning? If we try to visit this again, what is machine learning? Machine learning, at least so far we know is, so far we know is classification and then we have regression. So classification is all about trying to predict one of the target classes. So somebody asks you, can you build a classifier which predicts the face recognization so that camera can detect the authenticate a face? Regression is something about, you know, trying to predict the value. But are these the only two more problems in machine learning? Is there any other more? There are many others. But when we talk about generative AI, what is, what is one more? Very, very important. And that is called. So this is, people can build classification models which you are building in your assignment. This is something called regression model. Somebody asked you to predict the price of a house, Zillow app or something. They had actually regression model, right? Predicting the price of your Uber trip, right? Maybe a regression model. What about generative model? Generative model is where you're generating content. Generating content. And, and generating content means it could be different types of content, right? Like, you know, it could be, as for this definition, multiple forms of data. So what could be the different types of content that could be generated, right? It's. Is it, is it something that is limited to text? No, you can generate text, you can generate audio, right? You can generate, let us say, a video, right? And so on. You, you or you know, you can then create like relationships like text to audio conversion, right? Generation or maybe audio, Audio to text generation, right? Things like that. So these are the important things the generative model will do for you. Now why is, what is the main difference between a classification model and, and a generative model, right? So see, classification model, I was trying to tell you in the last slide is a discriminative. Discriminative model model. Basically it means that, you know, try to separate the classes, try to understand what is addition boundary between the different groups of categories of your data. That is the classification model. Generative models is objective is totally different. It's. It's objective is to understand your training data and based on the training data generate something similar. A right? Not duplicate. Very important. We don't want to generate duplicate content. I. I give thousand songs of maybe somebody like Enrique, right? And. And want to generate a new song similar as like Enrique sings. But it it. All the thousand songs which I've given it, it should not just copy. And again, I don't need a generative model to do that. It should understand what is the structure of data, how Enrique sings, right? And based on that it, you know, you. It should be able to generate with the same tone, pitch, style, right? There are many combination. Understand when you're generating audio, maybe a song, there are many things dependency. And your model should understand the dependency between all these attributes. And then it can only generate something similar. A song similar to Enrique, which currently we can see, right? Somebody you can ask, hey, can. Can you generate a speech based on previous leaders or something? And it will start generating the speech how they speak, right? How is the. Because the model has understand the distribution of the data and the features in the data, right? So there are different data points and there are different features. So generative modeling is extremely difficult process. And that is something is becoming started becoming popular in 2022, right? So that's. We'll talk talk more on that. But let's go back to the slides now. See, even before, you know, the simple thing, if we come back to the ChatGPT, right? If we, if we come back to the chat GPT, what do you think ChatGPT does initially, at least when you started using it, what was ChatGPT doing? Do you think it's generating text or it's generating the whole paragraph? Or, you know, when you ask a question, do you think it's generating the whole paragraph at once or it's generating word by word or a character by character? See the chat word by word, right? So if, if you look at Chat GPT, if you ask, hey, give me a story by Batman, all right, it will generate, it will generate something Batman was in, right? It will keep generating all these things, but remember, it looks at what it has generated and based on that it generates the next word, next word, next word, and so that it gets a complete paragraph, right? Right. So that is initially how the ChatGPT works. And the model behind this chat GPT is called Transformers, which I was trying to tell you, right? So Transformers is the main model that, that basically led to the chat GPT generation. Now coming back to the slides, how did this even happen? Right, so where, where did the transformers come in from? You know, to how, what data does it require? What is the basic concepts that we need to know, right? So the first thing is something called the world of nlp. Everything starts from the world of nlp, which is natural language processing, right? So in natural language processing, you know, you, you basically try to. And we are not doing nlp. I strongly suggest that you take NLP courses. You know, it's a semester long course. But in nlp, what you try to do is something called as tokenization. Now what is tokenization? Tokenization begins like, see, for example, you want to teach a model, right? Suppose you want to teach a ChatGPT model. Imagine that there is no ChatGPT model and you are giving it new data and you want to train it on Batman stories. So you pick up thousand Batman stories and now you want to teach a model, you make it, want to make it look like a chatgpt and you want to teach that. Hey, after you learn all these Batman stories, can you generate a new Batman story, right? So if you want to do that, the first thing you need to do is you need to prep your training data. And how do you prep your training data? You need to take all this thousand stories, right? Break it word by word. Each word becomes something like a token. Now remember that machine learning models only understand numbers, right? It doesn't understand your strengths. So everything will be broken down into a string, right? Sorry, a number, right? So maybe every word in each story line is broken into a word and all these words are broken, then every word is basically some kind of a token. And you have to come up with very intuitive algorithms where, you know, basically there is some, in a way that these tokens in are, you know, represent some kind of similarity. Suppose you give cat a token like 18 and you have a kitten. You should have a token very similar, maybe 19, which, in which in a multi dimensional space they are, you know, very close together, right? So you have to basically come up with identification of these tokens in a way that somehow you know, they have a very similarity. You can measure the, just by giving the token, you can measure the similarity, how close they are, how similar these words are, which is very important. Now why is this so important? Imagine when I type in something in chat GPT, I can Type something, right? I can type, hey, my name is Santosh. And somebody types, his name is Santosh. But these are all similar things. But the output of CHAT GPT, when you look at it's going to be very similar. Whether I have some words, I'm changing some words here and there, the meaning is still same. The output of ChatGPT is going to be almost very same. Why? Because the prompts might be different, but in similarity. If the prompts are almost similar based on the tokenization, if they are very similar, the output generated will be also similar. So the ChatGPT or generally any model needs to understand the similarity between these tokens to either generate or either to classify or either to do some sentiment analysis. Similar. Understanding the similarity is very important. And one of the models that helps with understanding the similarity is called word embeddings. So these tokens, word embeddings, it's all about taking your data, feeding it to a model, how to feed it so that it understands, extracts the relationships in a very better way. And then you train them, right? And what model do you need? You generally there are many models, but in the last couple of years I was trying to tell you Transformer, See, you look at the transformer, it's a very, very big model. It's a very architecturally complex model. And if you want to really go into the generative air field, you have to spend time understanding this model, just to understand this model, how it works. If somebody needs a video, you know, I can post a video on that, but we are not doing that in the class. You know, this needs some deep learning basics and just to understand the large language model multiple weeks. So. But I highly encourage, because the job space is very much into the generative AI and if you're going into the generative space, you need to know this model in and out. You don't have to design in the job, but you need to know how it works because definitely they will test you how it works. And that that adds a very important skill on your resume that you really know how this model works. So, so transformers is a big model where, you know, you basically use the word embeddings, tokenization, and with the help of the transformer model, you train a very, very big model, something that can turn into a chat GPT or maybe a model like Gemini from Google, right? So all this, the main technology behind this is transformers and the data processing or concepts behind this is something coming from NLP space. So these two things you have to know or to really enter into the generative AI space right now one of the, you know, so let's try to take a look at this year. So LLM scaling loss and LLM families. So see if you are going into the GPT worlds there are, there are many, many, many, many GPTs out there. You know, there are too many GPTs out there and like It's a chat GPT, there is a llama from Meta, right? This GPT4 is something from OpenAI, right? So, so you, you, you keep having these lot of large language models and these are all transformer based models. Like these are a little bit less. Robert A. Right, these are all transformer based models and if you just Google them or you go and check it in the hugging face, you will find a lot of models available there, right? And a lot of models are customized to do a certain thing. See when you go and ask ChatGPT, what could you ask ChatGPT hey, can you, can you under help me understand this assignment? Can you help me understand the description of this assignment or can you create a story? Sometimes you can also go and ask ChatGPT hey, can you generate the code? Now it will, it will try to do everything right? Because it's, it's, it's, it's when you, they might be training chat GPT they might have taken data from multiple sources, they might have taken data from finance, from web crawlers, from GitHub, you know, anything that was open, they took the data and the train. So universally could generate do many tasks. Now whether it's, is it an expert in that task? No, because suppose you just take a transform on model and then just train the transform model only on the GitHub code. Don't take the web data, don't take any news, don't take the other data, only the code. If you could take the code and generate, you know, train the transformer model, it will become a very expert in generating code expert than chat gpd because it is only focused on generating the code, it's not focused on the rest of the data, right? So if you look at the families, right you can take the, you know how chat GPT is built the knowledge but you can train your own models for specific tasks to give instructions to do some medical based GPT, to do some anomaly detection based GPT, right? So there are, there are different things you can do if you focus on only particular type of generation activity and the data right? Now I was trying to tell another important area here is something called as multimodal learning and its applications. Now what Is multimodal learning. See, in multimodal learning, you know, if you look at this diagram right on the side, basically what it tries to see is like, can you make a GPT model or a transformer model? Basically learn, right, what, you know, some relationship between text and image. Now why would you do that? For example, I would, I would, I would create millions of pairs of data points where each data point has a text and an image, right? The text is something. This is a beautiful house. And I will have a house. Then I will attacks. This is a beautiful, this is a, you know, awesome car. And I will have a Ferrari, right? And then I will have, this is a, this is Antarctica. I have an Antarctica image. Like thousands, millions of millions of pairs of text and images, right? And then I will keep training the model and while training the model, I will come up with an algorithm or put it there so that it tries to extract the information, the mapping between the text and the image, right? So once it does that, once the model is ready, how would you use this model? You could give a text, hey, can you generate an image of a dog? And it will try to come up with the image of a dog. Because from the millions of pairs of image and text, it has learned what is the relationship between words and pixels, right? It has learned that. So now when you, when you give a new description, it's automatically giving you an image because you trained it so, right? Also you can do the reverse. You could give an image and ask me, give me a text. It is able to do that because it has able to learn what is the relationship between the pixels and the textual words, right? So it is able to generate the, generate that as well. But this is, but giving training a model with more than one mode, right? Now what is a mode here? Mode is like the type of data. So here you are not just focused on text, you are focused on text, you are focused on image. Maybe tomorrow you could add one more dimension, video or audio, right? So multimodal learning is basically where you are making a model, learn on multiple types of data and generates me generate also multiple type of data, Right? Right. So that is multiple model learning. So if you go back to ChatGPT 2022, you didn't have all this multimodal learning. It was all text based. You give text and it will generate text. But when you look at chat GPT4, right, the 4 version GPT4, it's able to take all the multimodal data and generate all those things. So it's much, much smarter because the learning behind this is basically this. Now, now when you talk about the generative AI world, there is one very big, you know, model, something called as a diffusion model. Now the diffusion model is something, you know, let me see. Yeah, Diffusion model is something where you teach a model how to remove noise and then generate the image from it. So if you look at you basically during training, you give a noisy image, right? You give a very noisy image where the pixels are blurred and, and you teach the model how to remove this pixels and smoothen it and come up with a clear image over time, right? You keep teaching it with millions of images or thousands of images. And then over the time it is able to, you, you, you give a noisy image, it is able to generate a good image. You basically train it like that. So this diffusion models is one of the state of the art models in generative AI. Where see, we just saw Transformers, right? So one of the models which in generative space we saw is Transformers, right? The Transformers is very much focused on text based generation. Transformer is extremely helpful. Where you are, you are, you're dealing with textual data, right? And you, you, you train the model over maybe web data and you want it to generate new text or similar text. Then Transformer is really, really good. But diffusion models, on the other hand, it's another area where you are, you want to generate images, right? Or you want to generate video, right? So for that it's. It's a different model, very popular called diffusion models. That's, that's the state of the art. So for example, let me just. So, so how many of you know Sora? Does anybody of you know Sora, the model Sora? Yes, I just saw them. Okay, you just saw it. Okay, so so Sora, if you look at this, right, you know this is a really good generative model for text generation, right? And if you come down, there should be some videos as well, right? So it's not here. Maybe they change the. This thing. But there were really good videos earlier. Yeah, yeah, just try to search it. Sora is really good for video generation. And the one of the models it uses behind the scene is, is the diffusion model. So this is the model. It's basically, you know, of course they would have done a lot of proprietary things over here, but the basic model is diffusion model and the GPT2 GPT 3.0 is basically coming from the transformer model. Also the Meta Llama Gemini. All these are coming from the transformer model. So now it's really important to know these models at the Basic level like you need to understand what is a transformer and what is a diffusion model, right? At the basic level to really start playing around and working with this to create generative AI projects. But that would be a totally generative AI class. Again I will tell you the reason why we even talking about generative AI in big data class in the end. But these two models are very popular when it comes to generative AI. Okay, so we don't have to discuss all these things here. Let me go and look at the other. Let's also take a step back and look. Try to look at the. The history how this generative AI came into space, right? The development of AI reached a new level in November 2022 with the launch of Generative Chat GPT. Chat GPT. A chatbot took the world by storm and was built on top of large language model GPT3, right? GPT3 for research coming to also shook domain when it was released showing that models could learn from unsupervised data and then further new tasks without furthering training. Now what does this mean? See, we are focused in Assignment 3 about making a model supervised model. And I told you what is supervised model. As long as you have a data point, as long as you have a label for a data point and you're teaching the model, hey, this is the data point and this is the label, right? Then it's supervised learning. Many times in machine learning you have task which is unsupervised, like okay, somebody throws you the data of COVID patients, you don't know what are these code variants and they ask you to cluster it. Now you don't have a label but it's unsupervised machine learning problem. Similarly, in the generative AI space when you are taking all the logs, you are taking all the GitHub code, you are all taking, you know, lot of textual data, tweets and training the model. There is no label, right? This is all text data, this is, you know, all the data. But the model has to somehow understand this data on its own and based on its understanding, extract the structure, rent relationships, distribution and then based on that, generate the data, right? So this is basically unsupervised learning, right? So the models are running in an unsupervised learning. The race for supremacy. We began these models being able to respond in a human like fashion have bought the topic for AI into mainstream now. See, AI have been there for last 10 years or even before. It was there from 80s and 90s way, way before then the cloud Came and cloud. Because of the cloud you had good infrastructure so you could support the AI models. Then the phones and everything became much more from a hardware point, supportive of the ML models, they could start running. So you have the perfect infrastructure ready for these models to run. And then generative AI came and suddenly till AI, which was just talked about in couple of tech places, now it became everywhere. Even the enterprises, like small, small companies, they want to use generative AI to increase their productivity, right? So now because it's able to generate content, that was the main distinction earlier it was only about building a prediction model, a regression model, but now the opportunity with generating new content. That's why there are new startups coming in. Because what could be the opportunities? There's so many opportunities in the medical space, cyber security, just in the business, financial that you will generate so many content. So people are trying to understand what, what they could do. It's still early. All right, so what is genre? Gen refers to a subset of model approaches that have been trained specifically to generate new data. This is different to other unsupervised machine learning models that train to classify data samples or connect input values for regression. As I was just trying to right the history of AI models, how did we get there? You know, AI has been there for 50 years. We don't have to go self explanatory thing. These are some models, you know, history. I'm just skipping in the interest of time. But you can take a look at that again if you're looking at this back propagation. See, you know, back propagation is a very, very important algorithm in deep learning space. Now deep learning is something, you know, in machine learning, your assignments three, if you look at it, what does it do? You, you take the data analysis, do feature engineering, then select a certain set of algorithms, right. And then build a model. But deep learning is not deep learning is a subset of machine learning where what you do is like you pump in, take all the raw data, maybe enhance it a little bit, but you push all the data into something called these layers. And these are called deep neural networks, right? And these layers automatically does the feature engineering for you. So a lot of hard work which you are doing in the traditional machine learning, these layers automatically extract it. And you can use this to build, you know, machine learning, you know, basically predictive models or regression models. And yes, deep learning is the main model for even your generative AI. So the transformer model, the diffusion model, I was talking earlier, it is completely based on deep learning model. So somebody asks you, is large language Models which is transform more or diffusion model or you know basically CHAT GPT based models are, are, are, are deep learning models. The answer is yes, everything is deep learning. But the only difference between these GPT models or large language they are very very big. So these layers which you are seeing, they are too big. When you talk about the deep learning models now if you are entering into the Genai space, the first thing you need to show understand is data science, machine learning and, and then you know deep learning. And when you are doing deep learning students somehow skip this topic. Back propagation. If you're skipping back propagation, it's a waste of your time to study deep learning. You will just realize this years and years later that you have been wasting time. Because if, if you don't do back propagation and you don't understand it clearly, it's, it's not worth investing time in. Deep learning is extremely important. So one thing when you are doing deep learning is crack this topic as much as possible back propagation clearly understand the dissect it completely. Once you do that you will even understand the chat GPT very very easily. If you don't understand back propagation it is going to be tough. And back propagation is some something. Again I'm not teaching this year but it's only a way to how teach your deep learning models, you know, so to learn something and that's popular. It's basically a optimization and learning algorithm for deep neural networks. Right. So go back and see more on the back propagation. You don't have to go through this. So it just talks about how did you know we enter into the chat GPT world but so we were talking about back propagation. Right after back propagation there are some models like multi layer Perceptron. These are some functions. There's all coming from the deep learning world. And once all these started coming in there are some models that came Alexnet, you know that really good model for computer vision and gpu. This again coming from the deep learning mod space. But once the deep learning was evolving, right Back propagation with all the models coming up computer vision really becoming good because of deep learning, right. Once all that happened was happening in 27 there was a breakthrough and that was a paper called attention is all you need. Now what is this breakthrough? Attention is all you need is basically the transformers model. This is where the transformers was introduced, right? And what it does, what it did is basically until here there were multi the biggest problem in deep learning. One of the problem areas was something like this. So suppose, suppose you have to do a small thing like you know, video generation, let us say a video activity detection. No, no. What is video activity detection? So suppose you know now how do you detect the video activity? Something could be running, right? Walking, right? Sleeping. How do you detect it? So maybe you have a frame one, right? Then you have a frame two, right? Right. Then you have a frame three, right? And if you are. So everything comes in a sequence. So if you, if you understand what is frame one, if you understand frame two, it would be based on frame three. Then you might be able to predict, hey, this looks like running, right? So this is a sequential problem. What else could be a sequential problem? Something like stock prices, right? So let us see that. You know, today is 14. So if we go sometime back, right? 0614, right? What would be Nvidia stock, right? Then at 06, 15, what would be any Nvidia stock, right? 06, 616, what would be Nvidia stock? And if we keep doing this right until now, we might be able to predict, you know, if you look, we have the ability to keep looking so back and, and then able to predict what, what would be the price today. Then we have a really good model. But the problem with earlier deep learning models were they couldn't go very, very back. They could go maybe three or maybe 10, you know, 10, 10 data points back in the time to predict something next, right? You could only go 10. You, your, your window is only up to 10 or three data points. Not if you go more and more back. It's, it's, it has a forgetting problem, right? So many sequence based prediction problems. Sequence based prediction problems, right, which were being solved by models such as lstm. These are some deep learning models. If you look into deep learning, these are main models to solve sequence based prediction, sequence based classification, right? And they are not able to solve it. So then you had this. Transformers and transformers had the ability to look back, make the window really, really big, right? It could you give, see, look in charge, you give a full document, you give a full paragraph. It is able to look through everything and then generate the output. It's able to understand all the relationship between, right? And able to generate. So it has the ability to look back the content, very, very back and understand the relationships, understand the history. And based on that, it is able to generate it. That was the main innovation, you know, main technology. Attention is all you need. And transformers and with it everything started, right? That yes, we can generate a lot of data and we can have longer prediction problems. And all this thing came up now Just to, just to tell you, for example, suppose I want to write a story on Batman. What would be it like? Hey, Batman Begins, right? And I keep writing, keep writing, keep writing. But the way, you know, these generative models work is they look at this data and based on that they generate the next word. Then they look at these two and then generate the next word. Then these two and generate the next word. Okay? If we were trying to do this with something called as previous deep learning models like LSTM and RNN, maybe after 20 words we are here, let us say New York, Batman at New York. And you know, we, we, we basically at this place, the model will start forgetting about all these words. And so all the words that are coming after it will be something not accurate or it won't make sense, right? But if you were using transformers, right? Transformer has the ability to go really, really bad, look what's going on and then keep generating the new words, right? That's the advantage of transformer. So I know that we are not doing transformers because it's not a GENI class. Neither we are understanding what is diffusion models. We are just at the surface. But I really want to understand why is this important, right? This is important because it's ability to do clearly back and generate the new data points. That's why this model looked through a lot of records out there. Now with that model transformers, a lot of things came up. Gen poses a serious challenge to some fundamental model society. See generative AI. You know, let me also add one more thing here. Let me show you something called as. Just give me a minute. See. Yeah, if you are able to look this. Just let me show you one sequence here. So we were talking about lstm, right? Rnn. These are deep learning models that could be used to generate or classify data, right? But during this space, one of the most important model around 2014 was called GAP. This was also deep learning model. And this was, you know, it was a very disruptive model of the decade. Now why is it called so disruptive model of the decade? See, look at this. I'll just post this paper link also. Yeah, so now here, if you look at this, look at this. What does what this, you know, what is this is trying to do here? The GANS is something. Basically what it is trying to do is understand your distribution of your data, right? So with this model, what they were trying to do is like this is the original data, the one in the black, right? And the one in the red is something your model is trying to learn. Now they are training it Initially, you know, it didn't learn much over the iterations. It started learning a little bit more over the iteration it started learning bit more. But you know, finally it started to understand your distribution. What happens when you learn a distribution? Right. If you know your data is distributed in a way, then what could you do with it? It is basically learning a function, right? How your data is. Once you know how your data is, how it's distributed, you can start generating new data. New data. Very similar to the original data. That is important. Very similar to the original data. Not duplicate. It's duplicating. We don't need a generative model. You just copy, paste, use control C, control V. Done. We don't need a generative model. So it's extremely important while evaluating also a generative model that is, is it duplicating or it's memorizing or it's actually generating very, something very similar, right. So we want a model that generates very similar data. So if you look at here now during training, it's basically trying to understand the distribution of the data, but what is the use of it? Right? So if you. I think we came across this. This is a data set and this data set is basically pixel data set. Sorry, not. It's a MNIST data set where it's a handwritten digits. Now what you know, they tried to do is like they took this 50,000 or 60,000, I believe it's actually 70,000 images, handwritten images. They took it and gave it to Gan. Right. Again, was trying to understand how these model pixels are now distributed. Remember again, this image is nothing but, you know, a 28 by 28 matrix, right. And it's, it's just pixels between 0 to 255 where these 0 to 255, where it lies in the pixel that makes up this image, right. So it's between 0 to 9. Now these are thousands of thousands of images with little bit every, every image is different and everything is handwritten. There might be slight variations. And you're teaching the model basically understand the distribution so that the model could generate a similar image. So once the model was taught right, the Gans were able to generate something similar like okay, 9 028, which is because they understand the distribution of the data. Similarly, faces are also something very similar. Right. So they understood, they trained the model with some faces and these were the faces that the model generated. Right. So again for animals and. But one thing you understand, you see here is yes, it's when it comes to faces and some images, it's 2014 and the person who did this was Ian Goodfella. We been in multiple big positions like director of Apple also now. So what this paper basically tells us, yes, the ability to generate new content, right? And this was very disruptive. But the results, if you look, they're not so promising. Yes, you can still generate something, but it's not of high quality, right? And this is to 2014. But if you look at the research, right, Just give me a minute. Look at the research. Now this is something Stylegan, right? I'm giving you this link if you're interested. Now, Stylegans is, you know, a couple of years back, before the chat GPT, right? Look at the difference. The, the faces you can see here are very, very, very realistic compared to the faces, you know, the generation that is happening here. This somewhere in 2014 and this could be somewhere around 2020, right? Or 2019, right? And with this you can see over the years how the model has done really good. This was just before the chat GPT came into. Of course, with ChatGPT, you can see the GPT models are way, way better. But Gans had played a really, really big role in, you know, this generative AI. So GAN is also part of the generative AI model. So three models, at least till now, which I've talked about are in the generative AI space is one is transformers, right? So that they are really good at text generation, right? Gans are really good at image generation, right? And one more model which we saw was good at image generation is a diffusion model. So somebody asks you, what is generative AI? Generative AI is basically the combination of these models and concepts, which is the ability to generate text, right? You have transformers, the ability to generate Images, you have GANs and diffusion model, the ability to generate text and corresponding images, you have, you know, transformer plus a mix of other models, right? So this, this is, this is what is more you need to know what is generative because this is the core. Now with this models, what you can do, what applications you can build, right? What apps could produce, there is a lot of opportunities and that's a different topic. Applications of generative AI or agent AI, this is all additionally building on top of it. But when you come to the core, what is generative AI is the ability to generate content. And you all you need to know what is this content and who can generate which models can generate and how are they generating. If you know that, then you know generative AI, then everything becomes easier in the generative AI space, right? Okay, so let's go back now. Now you just saw that you know how realistic images were produced. And if you have searched this before, you know we have deep fakes, everything happening because of GANS and diffusion models. You can have videos of leaders, very big cyber security risk, right? They can talk anything, give permission, give authentication and employees can start using that for that, right? They could, they could be tricked into doing something, phishing emails. You can also generate malware. I mean, if you look at the cyber security field, malware content could be generated by these models, right? Now why do you think malware could be generated? Malware is nothing but a sequence of bytes. Your network data is sequence of byte hexamethal data. So as long as a generative model can understand the sequence of your data, whether it's bytes or bits, it can generate new similar bytes, right? So similarly you can generate a lot of malware content using. You can generate domain names. So there's a big cyber security risk. So a lot of, lot of problems with the deep fake cyber security. So there is opportunity with generative AI and there is also opportunity with trust. There is opportunity with fake records, There is opportunity with, there is not opportunity, you know, problems with trust, fake records and so on. So that's something we have to deal with. Now with gen, there is also a lot of job losses because you know, you have automation, routine tasks, everything gen is able to do it. You have new code editors, you know, that bring the productivity of developers really high. So instead of hiring five developers, you have only one developer, right? But with this you have also new job opportunities. So like as I said, when you're, you know, when cloud came, right, Everyone thought that okay, you know, there will be lots of jobs. But cloud administration, cloud deployment, there were new jobs created. Similarly, in the AI space, it will gen AI space, you need data, right? So they will how to create new data, how to, you know, create synthetic data for Genai training, you have jobs in that place, startups in that place, right? How to protect gen tools, how to make gen more explainable, how to make gen more responsible, right? What will be the gen applications in healthcare? Cyber security. So these are all new jobs. So there are a lot of opportunity in that space. We have to just upskill ourselves in the right direction and we should be fine. At least that's my belief. Right? Okay, so this is a wrap up of genre so far. So all we have just learned, if you know briefly talking just to summarize what we did so far is I could Say that we understand what is generative AI is basically generating similar content. That's the first thing. How does it happen? It's based on the type of content you want to generate. If you want to generate text, it's transformers. If you want to generate images, it's basically diffusion and generative gans and sometimes you could have hybrid models which could generate text and images as well. Right. So these are two top points we try to understand using these couple of slides here. Now does it stop here right now? Why is why I told you there are. You could generate deep fakes. You would do multiple good and bad things out of gen AI. Now, in context of big data, right? In context of data, what is the advantage of generative AI? So can anybody think what is the advantage of generative AI in context of big data? I would just say from my gut, the sky is the limit. Yes, absolutely. So yeah. Anyone else? Yeah, I will say a similar thing, that since it deals with big data, it's more powerful and getting more and more powerful every day. Yeah, absolutely. Yeah. So I'll give you some use cases here and look at this. So just give me a minute. See one of the things that you know in the big data, so in the big data world, you know, we, we were discussing something related to spark, right? So we have been discussing a spark. And what does spark is used for, right? It's to load big data. Load big data, right? Load big data, right. Second thing is ingest big data. Right. Third is to transform big data. Right. Fourth is to basically you could, while you're transforming, what could you do? You could easily clean the big data. Right? And then at the fourth place you can use to store big data. Store data, right? And so, so so many things you could use Spark and with the big data and then you could do to do analysis, right? Analysis 6 is building machine learning models. Yeah. So many things you could do. Loading big data, ingesting big data, transforming big data. Right. Now where does this gen help you now what is gen again? At a very, you know, one point always we need to remember is generating content. Okay, does it stop there? Understanding existing content. Right, right, right. If this is the case, what could you use it here in sp, can you build ETL scripts which is extract, transform, load. You have a lot of python scripts. Can you ask Big data, you can use generative AI to create scripts for your big data based pipelines? Yes, Genai can create those scripts. Right. It is like just create the code for me. So generative AI already helping in general Right. But in context of big data also it can create all ETL pipelines tools for you as long as you give the correct prompts. Right? That's one, one thing. So second thing is can it improve? Very, very important. Can it improve before improving can it analyze your data right now what is so lot of the lot of the analysis you are trying to do in your assignment 2 is basically univariate analysis, categorical, you know, bivariate analysis. All these things you were manually doing it. If you give you just dump your data to the model, you know, chat GPT model or something, will it do all the analysis for you and give a report? Yes, it's going to do that for you, right? Are there so charge is a generic thing but are there any libraries to help with you check this. Pandas AI, right? You can just give Pandas AI and you can give a CSV or something and then ask it to do everything for you, right? Lot of things it will automatically start doing for you. Doing a lot of analysis which as a data scientist we were trying to do. It will try to, you know, write the code and also decide which charts to generate. One of the problems is like you know, you have so much data which charts to generate which is the best chart for this. A lot of this thing AI will automatically do for you. The gen will automatically do for it. Does it stop there more things like you know, you have cleaning data. So you were doing light of outlier detection, right? You were fixing outliers lot of those things you can generate script, just throw the file and ask gen to start fixing this and genre will start fixing it. But again you need to check that, right? And you can also see what is your data quality and all those things with with the help of generative AI. So it doesn't stop there. You, you can ask to build the models, you know using MLIB and also you know, your generative AI will also help you there. So using large language models to help in building big data pipelines, that that's the meat here. So whatever you were doing as a big data engineer manually can you take the help of large language models to help you assist to do build this big pipeline? And the answer is yes. A big yes. And it's also happening in the industry that, that's, that's why you know now the problem here is I, I, I can't say with complete, you know because it sometimes everybody has a different take on this. But my belief is there are two jobs in the industry that more important one is a big Data engineer, right? Where you are actually using SPARK to build all this. You take the data, you build the pipelines and all those things, right? Making the data ready for very, very big models, right? That's big data engineering, right? The another big job is a data scientist, right? So where you are actually analyzing the data, bringing the model. Now with all the rise in the gen AI, all the productivity and all the tools, I believe you shouldn't limit yourself to a single rule. You should know both areas really good, the big data and data scientist because you will be unique and you have the complete end to end understanding and it is easier. Somebody says that, hey, I have five big data engineers. Well I want to cut off four but since you know data science and model building as well, they will retain you at least this is my understanding for enterprises. So know both areas, the data scientist and the big data engineer if in the long run, right? So now this is very, very limited, you know, knowledge and you know I'm just trying to share about like how Genai could help. But you know some of the students earlier said sky is limit, there is many, many many more things to come here. So knowing why what is Genia is going to help you in the big data, right? Okay, so now with that let's what, what we can do is now I hope you understand a little bit on the gen side. So with this what we can actually go and look at is the project. So here we have our project, right? And let me go to the first of all the hands on thing here. That is the GitHub link. Now, now let's try to take a look at this diagram and I explained that in the video. So I highly recommend that you go to the video and start seeing it. Now what does this, this open source project, what does it do? See it basically takes the financial API. So there is a financial API which is a real streaming API and Bite Wax is a streaming WIP plan. It's similar to something like, you know, your spark and what it does it, it extracts all the data, right? It extracts all the data. It's basically taking streaming all the financial data and it's converting into something called as embeddings. Right? And embeddings is something that it's, it's, it's a form of representation of data. It's not the raw data. So whatever you have in the financial news API, that's the raw data. It basically extracts something called as embedence which is basically understanding what is the relationship between different words, words of financial data, right? That is embeddings and that is useful train the gen model. The embedding is the cleaned and transformed data that you would use to build your generative model, right? So now embeddings can't. You know, it's. It's a, it's. It's a AI data. You can call it as AI data and this data, see you have to store somewhere. You are preparing this data to prepare a model, but you have to store it somewhere, right? So we are storing somewhere in. They are storing somewhere in Vector db. What is a Vector db? It's. You can call it as like a storage place for AI or AI database. You can call it as a database as well. Basically embeddings to store embeddings or run semantic search which is about similarity of these words. There are special databases and one of the databases is called Vector db. Similar database is called Pine Cone. They just hold your pre processed data, right? In these databases, once the data, the embeddings are stored here, what happens is this is a training pipeline where they, where they download a LLM. Now LLM is a large language model. You know, it's basically a transformer model. There are many transformer models out there. If you look at this documentation, one of the models they downloaded and now they train that model with this financial data, right? So they train it, train it, train it. And why are they training it? Right? They want to train it to make it as an app. In the end they want to make it an app. The app. What it does is you ask a prompt, you basically give a prompt, hey, can I invest in this talk? And it's going to respond something, right? So the idea is you take a GPT model, train it on the financial data so that it starts understanding the financial data as it keeps coming. And then through the app you are basically ask a question to the GPT model, not the GPT, the large language model here, GPT is very specific to open source. Sorry, OpenAI here it's a large language model, right? So we basically ask a question, hey, can I invest in the stock? And it will tell you whether you can invest or not based on how you trained it, right? So this is all the data that is required to, to train this model. This is the process data or embeddings that actually you feed into the model here. The model training specific to the financial data happens on a downloaded model, right? And once the model is trained, as the model is training, right, you have here the experiment tracker. What is the experiment tracker? There is a tool called Comment. See, there are different tools here, right? One is the apaca, I believe. Apaca where actually you're pulling the financial data. That's the data source, right? Second, there is a Bite Wax tool, right? Then there is a Vector DB tool which is basically storing your embedding data. So it's a cloud account you have to create, then you're downloading the data. This is all the GitHub code you would run on your spark on your cluster, right? The Wahab cluster. And this is a tool Comet. Now Comment is basically used to track machine learning model development. So whenever you are building a machine learning model or large language model, you will run some experiment. What are the results, what are the configuration parameters, how the results are looking? You need a dashboard that dynamically changes based on how many experiments you have run. You want to go to experiment one and check what changed with respect to experiment 10. All those things, all those metrics can be tracked through this tool. And this is not the only tool available in the market. Comet is one of the tools. Then there are popular tools like ML Flow, there are multi other tools, but in this case they used Comment, right? And then finally you have an app, right, which is basically the interface. Once this turns into a product, users can go and, you know, start asking questions and whatever product you have, that's why it's called inference. I always told you there is a difference between inference and training. Training. You train the model, but once you turn it into you deploy it, it becomes inference. You are not training it again, you are just asking a question and it will respond. It's like, you know, do you train a autopilot and deploy it on a Tesla car? It's deployed, it will start doing, you know, detecting pedestrians. Now you can keep training it in the background and keep putting the updates right? That you can always keep doing here. Also you can keep training the model and keep putting the model on the app, right? So training and inference are two different things. And if we have to summarize this whole process here, you are basically building a generative financial based app using generative AI technology, a large language model, and your data source is a real time financial streaming API. So in this project, what are you trying to do, right? You are just, you are understanding all the different tools you are getting. You, you basically get access to how to retrieve data from API, right? Some part of the code, some part of the code tells you how to break, break down the API into embeddings, where those embeddings are stored in the Vector DB in the cloud, right. Some part of the code is basically training your model during the fine tuning. Some part of the code is basically if you have done everything correctly in the end you will see a prompt. Prompt means you will see complete metrics where you can visualize what are your experiment if you've done everything right. And then you can also see, you know, some, some of your info inference pipeline. Now as I said in the video and I'm saying again there could be parts where it might break, right? It was breaking. It's okay as long as you're, you know, all I want you to do is try to do as much as you can, right? You okay, try to install. You know, making the cloud accounts is extremely straightforward. Like Alpaca, right. The. The Vector db. At least putting those screenshots should not have any problem. At least as long as you have that you should be good for from a grading point. But I still want you to go and run everything so that you have idea of how these modules work now because you know, sometimes this pythons everything little bit here and there break. You know, I, I told you at the start also don't get too much stress if something is breaking, especially in this project, right? Because there are too many components here. But I want you to learn like what are these tools? At least play around with them. If there is some error, okay, that's fine. Just put the error in the word file and I'm okay with it. But if you want to know more about it, contact me in the office hours because I know this is a complex project, but I put there here to at least at the surface level you can connect the dots and at least you know how to. How a generative AI model basically runs, right? That's the intent. And so, so please don't get unnecessarily stressed that if something is breaking because I have told again in the my video I tell that in the. At the starting of this I told you and I'm again telling it's okay but, but try to play around all the components as per the video and if any error comes, that's fine. Okay, so far, so far. Any questions here? Okay, so we'll take a quick break. If there are no questions, we will come back. Let me see here. Right, Let me actually go again on the list on the project one. So there are updated instructions here as well, right? In the updated instructions, yeah. So you know, setting up the, this is what, you know, setting up the quadrant here. Coming up with this screenshot. This should not be a problem. I mean this, this, this, you shouldn't be getting any errors. I don't think you would be getting any errors here for all the cloud API. So, so as long as you're at least able to do this, I'm, I'm really good. You know, at least you know what these tools are. Maybe cloning this also you should be getting an, you know, ODU cluster is, you know, creating an account. I've been trying to make multiple announcements. So you know, I've done that I told you earlier also to create the WAP cluster way, way back, almost a month back. So because I know that at the last minute would be a difficulty. Right. The video was available. Right. So this, this should not be a problem. But yes, I understand somewhere, somewhere down the lane you might get couple of errors and that's fine. But if you try to do it, you might get this, you know, this dashboard. In the end, if this dashboard is coming, it means that you followed all the instructions in the video and this, this otherwise okay, it's fine. And I understand because you know, some things might break because you're connecting so many things. But as long as you have, you know, at least the top things, top screenshots and, and you, you did something on the Wahab cluster. I'm okay with the product. Okay, so again, if you have any questions, just let me know and we'll take a break here. 645. 655. Yeah, let's, let's come back around, you know, 710 and we'll, we'll start doing the recommendation engine. Okay, we are back. Yeah, so one, one. I hope all students are back. Okay, so one thing I wanted to do reminders like an. Okay, so first thing, let me go to assignments. Some students are asking for extension for Project Gen AI and it's on July 15th. So based on multiple students feedback, I think I will extend this. Let me see the date here. Again, as I said, don't take too much time because if it's fine if you are having some errors, but as long as you're trying to, you know, we have tried to install everything. Some things work, something doesn't, that's fine. But don't take too much time because you have other, other projects and everything coming up. So I'll give you till Saturday, so. Right. So I'm extending this to Saturday. Your grades for Assignment 1. Assignment 2 already came up. Assignment 1, I'll release in a day or so. And yeah, your labs were graded or just see that if anything else is remaining and that will also come this week. Okay, so now that was about Genai extension here now the building the productive model assignment 3. See, you know one thing please try to I updated this here. Please take a look at the following week video under Media Gallery. SK learn mlib right? So this should be here. This is a really good video from one of my previous students asked him to give a guest lecture. It's you know, it's most on the MLIB and the sklearn, right? It's a one and a half hour video. Something which you know you can watch today after I do the recommendation engine. Right? So this is excellent video. It describes how to do SK Learn how to do mlib. So something for your reference. I've uploaded the code again. The links were broken I guess so. So I uploaded the code again. Here. Here is MLib IP, NB and Sklearn. If you. I will open up here. You can. You can just low upload notebook and from there you can, you know upload these notebooks once you download it from here. Now the notebooks are MLIB MLIB if you are using Spark. So he basically goes through like how to use Spy Spark. How to load data, right? How to convert into a SPARK data frame. Pre processing. Checking for null values. Summary statistics. Training. Doing some feature engineering here. Standards. Rescaling data then training the model. Testing the model, right. Printing the accuracy. A very simple but really good MLIB implementation. SPARK implementation of your assignment 3. And if you are using just Sklearn, right? So if you are just using Sklearn, this also a great code, right? Scikit learn right Clustering. He does just to look at the data. He tries to fit the data, scale the data, right? Please look at the video. You will get more understanding of what he did. But this is a good video reference if you are trying to do your assignment through. Okay, so the codes are available. The video is available for Assignment 3. We just finished the Gen AI part. Let me do one more thing. We have time for this it. What I will try to do is like I know we have Lab 7 and Lab 8 pending and I've extended due dates to August till. But since we just finished Gen AI, I want to take the opportunity and try to see because students were saying that they had some issues with lab eight, right? Last seven. We will deal later. We still have a lot of time for the due dates, right? So the lab 8 let's try to do it here and maybe in the next class I will try to work with you on the lab 7. Don't. Don't try to spend too much time fixing the errors. I will try to do it in the class. Right. You don't have to worry about it and waste your time which is a big concern. Looks like so. So I. I will do it. So focus on your assignments and the. Because if there is any errors I can at least tell you that what to ignore and what not to ignore. Let me upload this right. So Lab 8 Introduction to Generative AI. Yeah so my intent has all been trying to. I always run the labs in class. So that's why always it's clear. I know maybe I should. Maybe I got some feedback. So I will be improving the instructions here going forward. But in general I try to run it so you have video recording available. And I try to tell you that was little bit misplaced this time but. But otherwise I try to always do the laps first. So let's go through this runtime. So I'll try to change the runtime here. Change runtime and I will try to take a gpu. I'm going to take this gpu. Anything is fine. But I'll take a GPU and let's see. So this. This code is simple. It's just printing a hello statement here, right? It. It runs fine here. It's all. All. Are you guys able to see my screen? >> Speaker 2: Yes, I can see it. The Google. >> Speaker 1: Yeah. Okay. And then you have the TensorFlow GPU so it should run, right. All that's telling you is whether GPU is available or not. Right. And then we are just importing some pandas. There's some basic data analysis code generating histogram. Nothing about generative AI except looking at the GPU now. Google Collab. I'm. I'm just ignoring this. This code here. It just mounts the data there. I'm ignoring that. What we can do is come and install this here. Okay. This has started installing something. Let it install. These are the transformer diffusion models which I was talking about Generative AI right. These are the models. So basically we're installing libraries for these models so that you can play with some data generating some data transform or the diffusion model, the Pytorch. These are tools to work with the gen. So it's installing everything it a couple of minutes. Not couple of minutes, but certain time here installed all the libraries use CUDA basically tells hey, use CUDA on the GPU side. CUDA is the one which basically a framework from Nvidia that runs your code on the GPU. All Right. So related to libraries, versions and dependency. That's the same issue I encountered. Okay, so Matt, is this, this. Did this all execute for you? Okay, but so you were having error. Okay, okay, okay. Yeah. One thing is like, you know, we would have to. Again, I apologize for any, you know, these. I should have put it here. Always select the gpu. GPU here. Right. That might give some problems. No problem. Yeah. Okay, so now this cuda and then it's basically checking if the CUDA is working. Nothing fancy here. It's basically, see, you know, deep neural networks, when you are the. When you're working with machine learning. Deep neural network. Sorry, when you're working with deep neural networks, all your data is in tensor, something similar to numpy, right? So all are like arrays where you do all these tensor operations. Multiple multiplication of tensors. And all this code runs on gpu. So here we are checking whether this is running this. Yes, it's running. Nvidia L4 is the GPU. It's a result. Right. So it basically says everything fine to run your deep learning code. Right. And then we are ex. Now we are trying to download some GPT models. Remember I was trying to tell you that there are. There. There will be a lot of models available from, you know, maybe, you know, somewhere in the hugging face. So this will be downloading some diffusion model. We are downloading a llama model from Meta. We are downloading a GPT model, right. And a couple of libraries. And these are some functions we'll see later. Right. So we'll just execute this. We don't have to worry about what those functions do for now. Right, but let me glance over it while it installs. The first function is translate the text. So you'd expect that you give some text and it will translate the text. The second function is basically it generates like you give some text, it will able to generate some more text on it. The third one is image generation. So you give some prompt and it will try to generate an image. The fourth one is you try to give some text, it will try to generate the audio. And the final one is you try to generate. Give an audio file and it will generate the text. Now all these are, you know, generative operations, generating text, translating text. Right. Generating image. Also like generating audio from audio to text. All generative operations. So we first download models and use these models with some other functions to generate the data. First one what we have here is example is text generation. You give it some text. Once upon a time in a land far away and you give this text to that function which has the generative AI model downloaded. It's a pre trained model, already been trained. You're just giving it a prompt and you can see that, right? It's trying to first do something. So it's executing this function. Right? Let us see. It will generate the text now. So it generated once upon a time, this is the original seed text. And then from here it started generating all the data. It just started appending what it thinks could be a story. Right. So this is a feature for generative AI. You don't have to click on device reset, just ignore this and here. Now again I run this right here. Basically what you're trying to tell is you're sending an English text and it's converting into image. So another feature of generative AI, right? When you open the this function you will be using a model and the model will basically you're giving an input and it's generating into text. Another feature, another feature is here. Basically you are don't run execute this device reset. Ignore device resets. So does the previous code translate text to image? Does it do if for instance if I translate. Okay, so if I English to French. It's doing it. Okay. Yes, yes. So it does all the languages. Yeah, you have to put the settings, go and do the settings and based on the settings it will do. So for now the settings is all, all about English to French. And here in another case we are trying to translate it from English to Hindi, I believe. Okay. This makes life a lot easier. Imagine like translating from one language to another language. I did it in my master's thesis and it took me three months. Yeah, it's a lot of time. Yeah, absolutely. So here it should. This is the English and this is the Hindi. Ignore. This is not working right. We couldn't fix it. So please ignore this. But this should we had a fix it it will also generate an image. So ignore that part. There's the audio generation where you given, you know, text. It is going to generate audio file. So it's generating the audio file. Right. Again, the models we have downloaded using the gen model, that's important. Otherwise it's something you know, we are just doing click, click, click, that's not important. Remember what is happening inside the function here These functions are called inside the function. We have downloaded a pre generative model trained model and we are using the model to generate this. So here you can see that audio file is generated, right? This is all the audio file generated. Now same audio file. We will Give here and we will ask to generate it back to the text. So it says it's not defined here. It should work. Working fine. Okay, the name Transcribed audio not working Audio file path output dot wave there's given permissions for my Google Drive, nothing else. Let me see. That goes. So I just executed this. The. The one, the mount one earlier. I didn't execute it. I come back, it's not executing. It should execute this. Let me do a rev reset. What is happening? Okay, change run time, save reset session. Just in the interest of time, if you want to ignore that one, ignore it. But one thing I will recommend is you can either ignore this part. It's fine if you have error, but that should actually work. The other thing you could do is restart session and redo it. Sometimes if you redo it, it should work, right? Just make sure you are mounting it. If you're mounting it, it should work. You're still having issues. Just leave it. Don't worry too much about it because you understand at least most of the part how to generate data, different types of data using text. That was the intent of the slack. So as long as you are able to at least generate something, it. It's. You understand how to download the models, how to use it to generate something. What are the generative AI features? That is the main intent of this. Okay, the next under this lab was another notebook which is a clip notebook. Now if you look at the clip notebook, right, let me here also select the runtime save. Okay, let's execute that. Write three option queues in the install command queues. Let me. I'll try to answer that. Just let me fix this. So see here, you know what this code is doing here is see if generally in the classification problem, what do you do? You, you have a. You. You basically give an image. You, you try to tell, you know, can you classify it as a cat? Can you classify it as a dog? Can you classify it as a horse? That is simple classification problem. But look at here. This is more than that. You're. You're trying to give an image and you, when you're building the model, you know, generally when you're building a classification model, your target variable is. The labels are defined, right? These are target, variable, cat, dog, horse, right? And you build based on your training data. That will be your labels. And you build the model. But in this case you were giving an image and you want to classify it at one of these classes. Now these classes are something that was not part of the training, right? You're just coming up with a. It's a photo of a dog. It's a photo of a dog, a photo of giraffe. You are just grinding some text and you are saying out of these four texts which closely matches to this image, right at inference time. Now this is something a normal classification model cannot do, right? But with the help of gen AI and especially this model called Clip, you are able to give an image and you have a description of text. You can have 10 or 20 description of text and you want to give the check the probability of which text out of this 10 or 20 which you are given dynamically which was not part of your training data, right? Is very, very closer to this text, to this image. So something extremely useful and a very important feature of this text and image understanding that generative AI is able to harness and you can use for building multiple apps. Again, this is an example. You give an image and you randomly give some text. Hey, out of this text which is very closely related to this a normal classification model can again do. Again cannot do this. This is the power of generative AI right? So I I know now there might be so many questions like how does it. Do you know what Again this totally. You have to go for a generative AI class to understand the specifics of Clip model you have to go deeper into. But this is not a generative AI class. I just want you to understand it through this law the power and the features of generative AI what generative AI can do just to motivate you how how it can. What power it can bring to the big data, right? And and then if you're interested take a generative AI class so so you can go and dig these models deeper. But again as I tell you, don't rush into a generative AI without knowing deep learning. It doesn't fit. You have to know deep learning before you go into generative AI. Okay now few of the. So those were all text to you know, text relativity to images and let's see some diffusion model. Diffusion models are really good at generating images. So let's. We are downloading some of the diffusion popular diffusion models first here. See with the diffusion model you can give it prompt, right? Once you download a diffusion model a future it's city skyline at night, cyberpunk style and it will start generating based on the prompt it will start generating the images. We'll see in a minute, right? You can university with library. Yeah. The model can translate that text to image. Now this which one? The last one is quite important. The Rest of them are dependencies for that dependency code. So we'll execute the last one and explain what it does. So look at this very funky cyber funk themed Japanese garden with a koi pond and cherry blossoms. Okay? It's generating a text. The model behind the diffusion, one of the popular diffusion models we would have taken and we're using it, which is already trained to generate text to images. But now we are at the inference page, we're throwing a text, let's see what it generates. But when it's generating, look at that, it's going through a lot of steps. Now what are these steps? Initially at step 10, it's generating something like this. Step 15, like it's step 20, it's generating step 20. It's making it better, better, better, better. Right. In the diffusion, what it does, it has an image and it keeps reducing the noise. Right? And finally generates a high quality image. Now every model has its own generative process. When you talk about Gans, Gans will generate images immediately, right? It will immediately generate a image. Diffusion model will generate step by step. So both model have their own algorithm or own technique to generate images. Right? But diffusion models, you hit this clip model, there's multimodal model. Multimodal model model where you have text and image relationships together. Right. So again, the only intent of these two notebooks is just to introduce you to generative AI and the power and the features of generative AI. So later we can understand how they can be helpful in our big data. Right? So if you have not executed this lab, try to execute this lab again. I won't change. The duty is far, far away and only one lab would be left, I mean currently. And that would be lab seven. I, I will try to finish that next week. And extended lab, the video will be released this week with a due date of next week. So you don't have to worry about assignment, new assignment. There is no new assignment. It's just extended lab. I'm trying to tell again and you don't have to work more on it. So please focus on your last project and the assignment three. And please finish project one by this please. Okay, so with this we will go and we will quickly take a five minute break. We'll come back around 7:46 and we'll start recommendation engines. Give me a minute. Okay, so I'll come. Just give me a minute. I just some lighting issue here. Okay, let's. With all the knowledge we have for now is like what is sp? We understand what is data analysis? We understand some Part of machine learning. Right. We, we understand also what is generative AI at a very, very top level generating content. Another very important topic is called recommendation engines. And you know, look at the top five companies, whether it's Microsoft, Tik Tok, social media, A lot of lot of their main product is about recommendation engines. LinkedIn, right. Recommending connections. So how is this built? Right. Of course it needs big data, right. Netflix if you look at, they are also into recommending movies. So a lot of interesting applications that you can build using recommendation engine. And when we talk about big tech, they're mostly on, on the recommendation engine. E Commerce, Amazon, right. Doing recommendations. So your project is targeted towards building a recommendation engine. But again you, you have posted some. I'll go through that requirements very clearly. It's, it's, it's very straightforward. It's not that difficult. We are not making it too super complicated. I just want you to know how to build a simple recommendation engine. That's the intent, right. With of course with Spark. So overview of recommendation engine. You know, there are different types of recommendation engines. One is called collaborative filtering and one is called content based filtering. Now in collaborative based filtering, what you have is in collaborative based filtering you, you recommend users based on similar preferences. So suppose me and my friend try to watch a lot of comedy movies. If I watched a comedy movie, new comedy movie, most probably because my preference are similar to his, he's going to get recommended in that direction, right? So that is if those, those set of concepts and algorithms are, is basically collaborative filtering. Now content based filtering Content based filtering is more about where you, you watch certain content you're watching, you know, content related to thrillers. So you based on your previous content and not by any user, right? Based on your, what you watched previously based on your content, a new content would be recommended. Other other Applications here are LinkedIn based applications, right? So you have a lot of like recommending new new courses, recommending new connections in Amazon, recommending new products. Now how did evolution of recommended first generation knowledge based content based content Collaborative hybrid. So these are, these are generally based concepts. So content based and collaborative we just discussed. And hybrid is a combination of these two. You not only by similar users but also by previous content as a first generation. And then these are some additional algorithms based on the personalized algorithms. And once you inject deep learning into it, you know it becomes more, much more sophisticated. So other. But these two content based and collaborative are the most important ones. And then you're just building on top of it. Now what are the basic challenges in recommendation engines. The basic challenges here are. One is the cold start problem. So cold start problem is something. See, once you have once suppose you join in Netflix, right? You are a new user, any new profile. As soon as you join, what will Netflix recommend you? Nothing. It doesn't know anything about you. So what is going to recommend? Nothing. That's a cold start problem in recommendation engine. So what you have to do is it will ask you, hey, can you, you know, select few movies and once you start few movies, it might recommend something. Then it will watch your preferences over time and start recommending. That's one of the main problems with recommendation engine. Cold start problem. Then you have diversity, relevance, balance. Now your, your recommendation should be little bit noble, right? It shouldn't be something. Suppose you are, you are, you just bought milk from Walmart. Now next item that should be recommended is maybe X or you know, something like bread. But again it's recommending you milk. It's not a good recommendation, right? Then you have also sparse data. Sometimes you don't have all the preferences of the users, right? You don't know how, what, what their intent is. So you have only some data points and based on those data points you have to fill in the gaps and you have to predict what they might like. So that's sparse data. Sometimes you don't have all the history of what these users are doing. Then you how to evaluation metric, how to evaluate whether your recommendation is, you know, very popular or good. You build a recommendation for Netflix, but how do you know that you know it's working good? You might have to see how much users are engaging in the app. You know, what is the business metric. So that is a difficult thing to really see because in classification all you do is accuracy and you're done with it. But in evaluation metrics for recommendation engine is basically you need to make the user engaged and see your business value improves, right? So you have all those problems, privacy problem. Because recommendation engine you take a lot of data. Suppose in Netflix you're seeing what the user is doing. You're taking all this data, right? So you have to build on top of it. It's, it's a, you are, it's a little bit challenging to do that. Now Content based recommendation system is, you know, so, so content based recommendation system is basically looking at, this is like an app and let me just open the content based recommendation in SIM is basically. Suppose you have an app, right? And you have different apps installed and in the apps you have certain features, right? The one is for education, one is for casual and one app is based on the health, right? So based on what apps you have, you might the, you know the. If you take a recommendation engine, it will, it might do. Do a feature. So every app might have certain feature. Education here, casual, time waster here, health, healthcare, right? So every app might have a feature. And based on those setting, based on those features, you know, recommendation engine algorithm can do a similarity product or basically match a similarity and try to see if a new app would be liked by the user or not. How is this all done? Based on existing apps. So I installed 10 apps and each app might have couple of features. I might take all the features in each app, do a similarity score and that similarity score might be useful to see if a new app a user would be able to. Would be interested in installing a new app. Right? So that's because we are just looking at the content. Next is a collaborative filtering. So here in the collaborative filtering, for example. Yeah, so here, if you look at, look at this, maybe there is some kind of a score, right? Embedding space where all these movies are something fall under children's space. And there are some movies where adults and children also might like it. And there are some movies where you know that is more like by the adults, right? So there are multiple movies, but the space is different. So now based on this space, how would you, how would you come up with like, okay, this adult is going to like this Harry Potter movie or not, whether it's going to lag the check or not. So you, you have to basically build this embedding space. So suppose we are talking about Walmart, right? You have to take all the items and build an embedding space. And based on the embedding space, it's like a matrix. And once you build it using this matrix, you can start. You use it to recommend products to the users. So again this, to build this space you have to use certain algorithms called als, that matrix factorization. We'll go over that. But once you have this embedding space, it becomes easier to start recommending products or certain movies to the user. This is most on the collaborative side where you are taking the preferences of other users as well. While building the recommendation engine in the content base, you are not taking the preferences of other users. And hybrid based recommendation means you are combining both of the things, both the collaborative and the content based F. There's an algorithm. We are not going over this. We will go over that later. It's. It's basically the algorithm through how we, we can actually see how to build this matrix which I was talking about. So we need some time to do that. We skip just for a minute here. We won't go into that evaluation metrics I discussed. Let me, before I go through this, let me go through one thing. Okay, let's go through this. So Amazon Personalized is a. See a lot of times, you know, building big, big recommendation. Suppose I'm an enterprise, right? And an enterprise I want to recommend certain health based products. I'm not a big company, right. I don't want to hire staff, data scientists and build a model, right. What I could do is I can use existing services. So Amazon might have built a recommendation engine. They can give it as a service. I can paste something to the service and give some data and I can have an app that internally uses this service, right? So it can start helping me for my customers recommend some health based products. But Amazon. So Amazon Personal is one of the recommendation services right now. Yeah. So let's, let's take a demo of the cold start problem, right? So here Magic Movie mission recommending movies to the users with Amazon Personalized we use the Amazon Personalized to start recommending movies. So we do a start. In this game you play the role of a user looking for a movie recommendation. Initially, Amazon Personal doesn't know anything about your interest. This is a cold start problem. Suppose you, you take a subscription Amazon prime you Amazon prime doesn't know anything about you. So how would you start recommending? That's to show your interest in different movies. And Amazon Personal learns of what you like find your recommendations are personalized for you. So we'll click on continue. So what it does it as soon as I become a new user I can choose any user, right? It starts with a cold, cold start for Amazon Personal. Welcome super movie fan to the movie machine. Without interaction data for a super movie fan, Amazon personality doesn't know what movies are relevant to them, right? So in this situation Amazon Personal initially shows the most popular movies and then learns from super movie fans. Next choice select on this I can select couple of movies that shows my intent. Like I might like something action related movie. These two, right? So so right. Yeah. And based on the C. So I've selected around five, right? And then I will say okay, you know this is my preferences and as I click on see recommendations it's using my preferences, it's using my viewing history and based on a few data it started running the algorithm. Now there are multiple recommendation system algorithms that can run behind one of the basic algorithms is ALS which we have to see. And based on this it started recommending me few few movies right now. I don't know except Batman because rest of the them are Independence Day. I guess that these are some related action movies. So sometimes it might be doing the right recommendation, right? So this is about a cold start problem and a small demo of, of you know, what could be in real world. Okay, one more thing that is important here is this diagram and what it does here is look at this. See Netflix. A lot of Netflix infrastructure is actually deployed at Amazon. So Amazon is a cloud vendor and you know you it has a lot of good data centers where you can deploy machine learning based services or in cloud services and all those things. So even Netflix all the infrastructure needs to be deployed somewhere. So they are using a lot of Amazon to do that. So if you look at at least a couple of years back, I guess this diagram how their engine works is, is see this is the user, right? And the user is basically doing play so interacting with the device data and a lot of other things. And the data gets, you know, a lot of, lot of device data gets generated, right? So millions of customers are using Netflix and all this data goes to Hadoop. Hadoop basically breaks down these services, right? So break down this content, right? And once you break down this content, Hadoop, I told you it's equivalent, I mean equivalent of Spark. It's doing the big data analysis there. It's breaking down your content, cleaning, transforming the data, preparing the data for the machine learning model. All that is done with Hadoop which you can also do with the Spark. So all the big data which is generated by millions of user has been harnessed by Hadoop clean and put and you know, made it ready for machine learning. Here the offline computation, basically the recommendation engine, you know, whether it's collaborative or content based, building whatever Netflix property algorithms are will take use of this big big data which is made ready using Hadoop framework and they will build a recommendation model behind the scenes once and some of the data sometimes might get stored in places like MySQL or Redis cache. MySQL is a database where you might want to store databases for clean data. You just want to put some dashboard, nothing to do with machine learning. Very, very crystal clean data just for a dashboard like how many people watching in the last one hour. It's just some aggregates so you can store it in relational databases. Sometimes you want to put some data into cache. Redis is a big data tool like cache where you, you, it's a memory. You put some key value pairs and websites can pull that information immediately instead of fetching it from database. So these are called in memory databases where you don't hit the database directly, but you take the data from. Directly from memory, right? And it's pretty fast. It could be supported by websites like Amazon, which have to be very, very fast. So they don't have to always go and touch the database. They can directly take from memory. Similarly in Netflix. So, but here the recommendation engine is built offline. And once the recommendation is built offline, you push the recommendations or watch this movie to the users, millions of millions of users, right? You're getting the data. As soon as you're getting the data, the recommendation engine is built. So, but remember, the recommendation engine is when it's built, it's built from lot of, lot of data. And it would have taken many hours, a couple of days to build this model, right? But once the model is ready, do you think we leave it that, you know, we are pushing recommendation? We leave it that? No, because my viewing history keep changing. Today I'm watching comedy, tomorrow after a couple of months, I watch horror after horror. Maybe I'm watching romance, right? So, so it's, it's like just, it's changing and with the change, you know, it should pick up that change in real time, right? And adjust according to my, my viewing history. Millions of user. But the recommendation engine should change for my personalized viewing and start pushing the recommendation. So it's a cycle and it's an online process, right? It's online learning, basically. See, if you train a model and leave it, and it always is, you know, recommending, that's a static model, right? But online learning is where you keep retraining the model again and again with the new data. That's more challenging and that's more needed in the recommendation engine. It's also needed in fields like anomaly detection, cyber security, because the malware keeps changing. But it's not that much as a recommendation engine, right? Real estate industry like Zillow, right? People, their habits keep changing. You need to keep Model 3, retrain it, but again, you have some time to retrain the model. It's a seasonal maybe, but stocks, stocks, you have to be very fast. Your models have to adapt to the new changes immediately. Otherwise you might predict the wrong prices. So this is all online learning. But look at the big picture here. The big picture is millions of millions of users pushing the data. You have to stream the data either using Hadoop or either Using a big data tool like Spark. Hadoop is disk based, Spark is memory based. Much faster. A lot of libraries are within one one framework. So from a testing point you won't have problems with Spark Hadoop. All libraries are decoupled, right? You will have problems here. It's a unified stack engine, right? Spark, you have more, more machine learning. All, all good performance. We will see how performance is very, very much better in Spark. So you have Big two data tool to stream the data, ingest the data, process the data, make the data ready for machine learning. And you maybe use MLIB to create, you know, and Hadoop, you have different libraries. Create the recommendation engine. Once you have the recommendation again, you have to push the recommendation engine so that it goes to the app. This is a complete cycle. So there's a high overview. Why are we learning all this thing? If you look at this big diagram, there are a couple of jobs out here bring making the UI client is all web mobile developer jobs, right? But here the Hadoop and breaking down the data, streaming the data, making it ready for machine learning. This is all big data engineering jobs, right? There's all database jobs here. All right, here is data scientist job, right? So now in our class we are, we are dealing with the Spark, the big data engineering a little bit about also the recommendation engine engine AI. So it's, that's why I try to tell you we are, we are connecting many dots here because it's all needed for the big data space. If you don't know this, then you won't be able to connect what is the power of the Apache Spark, right? So this understanding the big picture is very important to see. Where do you want to go from here? You're learning all these things, you're learning the assignments. But where do you want to take this? Right? So you want to take this to some carrier, whether it's data science or big data or both. So visualize this diagram so that you have a roadmap to build on this course. So we have to still do als and we won't do it today. I'll go through the assignments once again. So project two right here. See this is your project and the due date is August 4th. I am making it August 8th, give more time and that's the last date. Right. So. And initially we decided that this is an online presentation through Zoom. But last time when we discussed about it, right, we said that one. Assignment 3 we will go with online. So this is recording, recording video presentation. This is a small update I made. Yeah. If we Go through this. See, there are few resources here. This is, this, this video talks about more in detail about recommendation system it's designed. These are really two good videos which I posted. And you know, what are the basic types, the design considerations. But yeah, this is, this is for a lot of information if you want to dig more into recommendation engine. But this video right here is extremely important for your project. It's called Building a Movie Lens recommendation system. So they have a notebook, right? They download the data, they go through how they build a recommendation system, right? Simple steps of how, what are the data sets, how what algorithm did you use, how are they able to finally evaluate it? And one of the challenges is which is a good data set. And I highly encourage students to look at this data set, Movie Lens data set. And there are a lot of articles, a lot of blogs on how to build a recommendation system using movielens. Right? So there's a lot of resources and that's fine, that's good because you're, if you're doing it for the first time, you need a lot of resources that can help you. So, so that's why if, if possible, if you have a lot of machine learning experience, try to use a different data set you're doing for the first time. This is a good video that will help you build it. Also this is a, you know, a lot of blocks are also available to build it. So I highly recommend using this infrastructure. Please use use Data breaks. It's up to you Google Collab. It's up to you databricks. Problem is sometimes you might not be able to install some libraries and all those things. So maybe you're going to Google Collab with you. If you want to use Wahab cluster, it's up to you Infrastructure totally up to you, right? All you need to do is finish this. Use Spark, right? So this video is using Spark. So use Spark libraries, record a presentation, submit your code and this is on August 8th. I will talk more next time as well. Now one thing I will try to do this week is let me go to the assignments again. So this is your project. If you have any questions or concerns, please let me know. Don't wait till the last minute, right? This is pretty clear. If you look at this video, everything will become clear. Focus on this video. Building a Movie Lens recommendation system and you a lot of things will become clear. Now assignment from from assignments point, right? We have assignment three coming up next week. And you know, see in the lab six, I tried to explain something. This one last week, this I Haven't explained but you might have executed it. There's lot of code in here for related to Recommendation engine. Also if you are doing assignment three using Spark, lot of code is there, right? And the lecture wise also there is a slide I still have to go through. So what my plan is, I'm. I'm. You know, I will. I will try to create a video and release it in the next two days. Right. Related to Spark and ML so that it's. I'll try to do that within two days and. And post it. There might be a delay by when because of many things going on. But I'll try my best to release this additional video. But you let me go to Assignment 3. This should help. But once I release a video that might help you with some of the questions students are having. Because I had some students in the office hours ask me some questions. So with all that feedback, I want to create a video. So I want to take some time creating that in the next two days. Now assignment. Once we look at assignment three, right. Please look at these two notebooks. If you are doing any using Spark, this is the notebook. If you're doing using SK Learn. This is a notebook from a previous student. And this is the video where he explains how to do it using Sklearn and Emulate. That might be really useful for you. Right? And now let's quickly. Let me do something here. It's just a very, very. Just to show you that it's not that complicated. Let me try to do something. It just came to my mind. So just give me a minute time frame. Okay. Am I sharing my screen? No. Okay, see I am asking you to build a classification library, right? And I have also explained the code for Sklearn last time and we have more code explanation from another student as well as the notebook. So a lot of support here. But let me try to do one quick thing thing. So I might have some data. Okay. So I. I'm uploading a CSV file. It's just a diabetic data CSV file. And we'll see what it does. Right. So still uploading, I guess. Okay, so there's some data. And then look at here, right this all the data and then there is something called readmitted or not. Basically it's a prediction that if the patient is going to get readmitted based on all this details in the hospital, sometimes the patient the prediction is like okay, no, you know, maybe in less than 30 days, greater than 30 days. But that is your target variable, right? And you can Use this data to model whether somebody would be readmitted in a hospital for diabetes condition. Right, so this is, this is the data and you might build a classification problem around it. Now I'm not trying to go very deep into this. We try to that do that in a real class. But what I will try to do is I will, I'll just try to see, you know, it just came to my mind if this can ease things out here and help. Right, so. So let's say, you know, begin by loading the data set, discuss whether the data sets fit memory or something. If we come here in Google Collab and we basically say right, same thing right now we don't have to discuss whether sample was required but for diabetic CSV data. Right. And I just say enter generate with AI. I can use generate with AI and enter while what is the problem? Not fetch folder. Okay, let me do this again. It. There is some logging in Google Collab. Just give me a minute. Logged in again. It. Yeah, so it. You see that you can start using AI to just load it because. And I encourage it to use it in Collab because I, I'm. We are not actually trying to solve a Python class here. It's not a python class where I'm trying to. I just want you to ensure that you are able to connect the dots here. So. But see in your presentation you should be able to tell what you have done. That's that's more important for me. It's not about the code. But of course you need to still submit the code because I will review the code that at least you did what you're claiming to you have done. Right. So now this starts with the data set data loading and then analyze data characters for the univated month to be date analysis. Right. So if I go to the Pandas. So I go here again I say, you know, generate with AI and generally it should do. I don't know, there is some issue that's coming up not Fetch Google Resources language code. So should not have this issue. I don't know. There's something problem at my end. Yeah. So it's trying. So let me execute this code right. It. Right. It executes nicely. It's able to load it. So it's not difficult as it is. Right. Then it's checking whether the values are null. Right? It's whether checking the missing values. A lot of code is automatically class distribution code is automatically generated. Right. A lot of things it's directly helping you. So you know, if you see that, you know what are the missing columns for column Right. Value counts, lot of other things. Class distribution. No is 54,000 records less than showing all the. It's showing you the outliers, box plots, things like that. Right. Now take. Take it a little bit more. Describe the steps taken to. Now go here. Yeah. Prom. Describe the statistical handle software constancies. So looks like there is nothing it couldn't. So it just describes this text but. Right. Yeah. So it's applying all those things, cleaning the data, filling any. These are some things we discussed. Right. So how did we. It's filling with something like unknown if the missing values are there sometimes it's filling with another missing value sum imputing. It's identifying, it's applying. This is the interquartile range. Right. For how to find the outliers. Right. It found the outliers in your data set and then it's printing the outliers. It's fixing the inconsistent data if it's there, you know, you have to again generating the code is one thing. Whether it's generated correctly, whether to find whether it's actually working for you and you know, making sure it's connected. That's all you have to still do. It's not just things won't otherwise you won't create the story. So as I again said, code is not the problem. Understanding the code and connecting it is more problematic than. Because now we have all these tools and I'm always up for using AI because that's something you're going to use in the industry as well. So now see, I told you there is some line of code problem here. So we'll skip this. We'll skip. We'll skip this. But you might have to fix that. Right. I'm just giving you some pointers here. So now that is done. And this is also always again you did it. So present some, you know, tools. So up to here you already know it because you did it in Assignment 2. So it looks like the way you prompt it is going to be different. That was the error. That's a bug here in Google Collab. Okay. Generating. I don't know if it's going to work. It's not working. That's making it work is a problem. Now it's working. I just push pasted the error also so that it regenerates the code. Let's see what it's doing. See it's generating a lot of things which otherwise takes many, many, many hours to generate. Right. So but you need to understand what does it do while you're explaining, you know, at least you need to fix these errors. Understand this code because you're presenting it. So now, now, okay, this is all done till here it was just analysis and we just took a simple data set. Always like feature engineering, right? So we don't have to do the PCA part. As I was telling in the class. So look at this here. So here it's taking something. Let's see what is the simple. At least feature engineering is suggested by. Here. Readmitted. Dropped readmitted. Right. Feature engineering here basically encoding the categorical variables. So one of the. We have a categorical variable, we can import it. Right? So it has automatically added it. Rescaling. I always try to tell about you might have to rescale the data. So it's generating some code with the standard scalar for it, right? And it's creating the pipeline. Now either you select everything, but whatever you're selecting you, you need to explain what you did. At least that's even a one line of code. That's fine, but please explain what, what your intention for feature engineering is. Whether your feature engineering is dropping two columns or maybe modifying existing column or you think nothing is needed. Maybe your data set columns are too less. Tell me why, what did you do for feature engineering? Why do you think that is the most appropriate thing to do? So again it's an open ended question. You know your data set better. I don't know your data set. I'm just trying to see what rationality you are adding here. Right? And then split the training data. Okay, I. There is some error. I think you were to try it. There's something going on. Okay, it's generating data. Now there's nothing. But last time what I was trying to show you, it was already built up code. This time I'm just showing you that on ad hoc that you know, could use AI to do a lot of stuff here. So it's basically splitting your data. X train, Y train. Right? And it shows you what it does. It's always explaining you the code, how it's doing the cross validation. All right. And finally the performance evaluation. Performance evaluation. We only care about the confusion matrix and accuracy. So if you come down. Okay, so here, see, you know, it's generating some code. Basically what it's doing is you would have created your model earlier here you might have created your model. This is your model and you're giving your X data all data and it's predicting the Y. This is what you want to do, right? You want to basically once your Model is ready. You want to give some your test data and it will predict the Y prediction. And once Y prediction you have, you can give it to the confusion matrix. Confusion matrix is where basically you give the original data and you give the prediction data. And with this you, you basically create a confusion matrix and you can print the confusion matrix. And if I, I don't know whether this code will, it's not working because things are a little bit broken here. But I hope I showed you confusion matrix last time. If I, I believe that I did. Let me go and see. This was the code I was trying to explain last time. Already you have this code, right? So, and here somewhere down right, this is a classification report. Basically you don't have to worry about precision recall. All we need to understand is what is the accuracy of your algorithm. You can use classification report to print it and then again don't use deep learning and all those things. But, but you can use this code somewhere here, which is the confusion matrix. This code, this code is basically prints confusion matrix which basically tell what is the actual class and what is the, you know, the predicted class. And it helps you to understand how your, why did your accuracy is not. Either it's too good or either it's bad. Confusion matrix helps with that, right? So you can again, you know, you can again use this Google Collab feature where basically you could generate with AI and that might help you if you have not done so. But some students who are not using it, I encourage you to use it. It might accelerate the process. You can focus more on the results and observations. That's more important because that's where the meat is like why are you using this? What did you observe? What could have you done better? That's what I want you to learn more, more than the coding part, because the coding part you can try to do a lot with the, you have the code reference code, you have can, you know, you can generate it with a little bit AI, you can combine things. But observations is the key here. Right. Again, I will, I will try to make a video which is, you know, addressing some of the students concerns which they were talking about. So I will, I will try to make a video on machine learning and, and release it in the next two, two to three days. Maybe two days, right? Yeah, yeah. Other than that, we will. Anybody have questions? So far, no. Okay, if you run into any issues with your assignment three, just let me know. I write my office hours are till Thursday. Again, you're running issues with your project or you know, maybe something Use the office hours. I'm. I'm available out there like it's up to Thursday. Right. And again we can do an appointment also but, but please don't wait till the last minute and get stressed because then it's, you know, hardly we have, it's difficult to connect on the weekend. Right. Okay, then we'll, we'll see you next week. And I will release the video for two things. One is the machine learning and the extended lab as well. This week. Right. Okay, thank you everyone. Bye. >> Speaker 2: Professor, I had kind of while I was doing the Gen project I just had a slight question on if how this pipeline can be used for other training models of like say sensor based things for like a lidar like multiple lidars of training those types of models. >> Speaker 1: Yes, yes. So. So I think you could still use the pipeline, I mean still the embeddings. So LIDAR is sensor based data is a tabler data. >> Speaker 2: Say it one more time professor. >> Speaker 1: Is it, is it tabular data? You're dealing with it. >> Speaker 2: Yes, it would be mainly image data probably working for like trying to do pre processing of getting rid of a lot of those outliers. >> Speaker 1: Yeah. What I would do is if you really, I mean of course this is a good idea to explore this pipeline for another data set. What you could, since it's open source, what you could do is like you know, use this code and try to first understand like what the high. At a high level. What. Because if you go to the GitHub repository, it has multiple modules what each module does. Maybe give, give it to a, you know, something like AI or something it will tell you at high level you know what this code does. You don't have to go into deep specifics but know which is the gen AI module, right. Which is the model training. Where does, where does embedding where you extract embeddings from the data. Here you are extracting embeddings from the financial data. There you would have to extract the embeddings from your sensor data. So you could repurpose most of the code but you might have to make some few tweaks and I think you, you should give it a shot. I mean worst case something doesn't work but you might will end up learning very well. You know many things. But I still believe that it might, it might work. But what do you, what do you in the end want to get from it? What was your final prompt once you tail. >> Speaker 2: So right now I was kind of how I was just sketching it out. I was doing this is the sensor data would more of take the place of the real time streaming data from Apache and the the training model for the financial data that would be more replaced with a physics based model for. I wanted to use this as a navigation loop like a PID controller. I was trying to go and detect like waves like wave position like exact of it and troughs through a kind of sensor fusion model of using upward facing sonars and downward facing radar. >> Speaker 1: So like your prompt, what would you prompt for it for? Like once the model is trained. >> Speaker 2: It would be more of for adjusting. I think the prompts would be going in of if do I need to be adjusting like speed or ride height based off of upcoming sensor input. >> Speaker 1: Okay, so you want to. You you. Based on the sensor inputs you want to adjust certain actuators or. Right? >> Speaker 2: Yes. >> Speaker 1: Yes. Okay. Okay. Okay. So. So based on the feed of sensor data you want to adjust. That's an excellent use case by the way. Yeah. And you want to do added streams and for a physics experiment you should actually definitely try it. It's very interesting. Yeah. I believe that you might hit some hurdles. Try to use AI a lot. It will save you a lot of time. Right. Whatever. It's AI tools you have. Try to reverse engineer the code faster and try to see you know how to. Instead of financial data, AI can make the changes to fit your sensor data. Right. So that you can at least for the first iteration at least you might have some bugs, but you might at least come to know whether this is connecting. I believe that you might have some success here. >> Speaker 2: I'll write some proposals and email you. >> Speaker 1: Okay, great. Great. Awesome. >> Speaker 2: Thank you professor. >> Speaker 1: But excellent idea. Thanks for sharing. Okay everyone, then we'll meet next week And I said at least two videos. At least one video should be open up in two days. That's the machine learning extended video. I'll try to make that happen also this week. Okay then. Okay, thank you everyone. Bye. Thank you. See you next week. 